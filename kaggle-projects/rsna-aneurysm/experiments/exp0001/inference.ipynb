{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RSNA Aneurysm Detection Inference - exp0001\n",
    "\n",
    "**目的**: テストデータでの推論とKaggle提出\n",
    "\n",
    "**実行内容**:\n",
    "- 学習済みモデル読み込み\n",
    "- テストデータ推論（TTA適用）\n",
    "- アンサンブル予測\n",
    "- 閾値適用・提出ファイル生成\n",
    "- Kaggle API自動提出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 基本ライブラリ\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import yaml\n",
    "import json\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "from datetime import datetime\n",
    "import subprocess\n",
    "\n",
    "# PyTorch関連\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torchvision.models as models\n",
    "from torch.cuda.amp import autocast\n",
    "\n",
    "# 画像処理\n",
    "import cv2\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "# 進捗バー\n",
    "from tqdm import tqdm\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# 設定読み込み\n",
    "with open(\"config.yaml\", \"r\") as f:\n",
    "    cfg = yaml.safe_load(f)\n",
    "\n",
    "with open(\"evaluation_metrics.json\", \"r\") as f:\n",
    "    eval_metrics = json.load(f)\n",
    "\n",
    "print(f\"Running inference for: {cfg['experiment']['id']}\")\n",
    "print(f\"Model: {cfg['model']['architecture']}\")\n",
    "print(f\"Recommended threshold: {eval_metrics['recommended_threshold']:.4f}\")\n",
    "\n",
    "# デバイス設定\n",
    "device = torch.device(cfg[\"environment\"][\"device\"])\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# モデル定義（学習時と同じ）\n",
    "class AneurysmModel(nn.Module):\n",
    "    def __init__(self, model_name=\"resnet50\", num_classes=1, pretrained=True):\n",
    "        super().__init__()\n",
    "\n",
    "        if model_name == \"resnet50\":\n",
    "            self.backbone = models.resnet50(pretrained=pretrained)\n",
    "            in_features = self.backbone.fc.in_features\n",
    "            self.backbone.fc = nn.Identity()\n",
    "\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(cfg[\"model\"][\"dropout\"]),\n",
    "            nn.Linear(in_features, cfg[\"model\"][\"hidden_dim\"]),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(cfg[\"model\"][\"dropout\"]),\n",
    "            nn.Linear(cfg[\"model\"][\"hidden_dim\"], num_classes),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        features = self.backbone(x)\n",
    "        output = self.classifier(features)\n",
    "        return output\n",
    "\n",
    "\n",
    "print(\"Model class defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 学習済みモデル読み込み\n",
    "models_list = []\n",
    "for fold in range(cfg[\"cv\"][\"n_folds\"]):\n",
    "    model_path = f\"model/fold_{fold}_best.pth\"\n",
    "    if Path(model_path).exists():\n",
    "        model = AneurysmModel(\n",
    "            model_name=cfg[\"model\"][\"architecture\"],\n",
    "            num_classes=cfg[\"model\"][\"num_classes\"],\n",
    "            pretrained=False,  # 学習済み重みをロードするのでFalse\n",
    "        )\n",
    "        model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "        model.to(device)\n",
    "        model.eval()\n",
    "        models_list.append(model)\n",
    "        print(f\"Loaded model for fold {fold + 1}\")\n",
    "    else:\n",
    "        print(f\"⚠️  Model file not found: {model_path}\")\n",
    "\n",
    "print(f\"\\nTotal models loaded: {len(models_list)}\")\n",
    "if len(models_list) == 0:\n",
    "    raise FileNotFoundError(\"No model files found! Run training.ipynb first.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# テストデータ読み込み（仮のパス - 実際のデータ構造に応じて修正）\n",
    "data_dir = Path(cfg[\"paths\"][\"data_dir\"])\n",
    "test_df = pd.read_csv(data_dir / \"test.csv\")  # 実際のテストファイルパス\n",
    "print(f\"Test data shape: {test_df.shape}\")\n",
    "print(f\"Test data columns: {list(test_df.columns)}\")\n",
    "print(\"\\nFirst few rows:\")\n",
    "print(test_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# テスト用Transform定義（TTA用の複数バージョン）\n",
    "def get_test_transforms(tta_type=None):\n",
    "    base_transforms = [\n",
    "        A.Resize(cfg[\"data\"][\"image_size\"][0], cfg[\"data\"][\"image_size\"][1]),\n",
    "    ]\n",
    "\n",
    "    # TTA transforms\n",
    "    if tta_type == \"hflip\":\n",
    "        base_transforms.append(A.HorizontalFlip(p=1.0))\n",
    "    elif tta_type == \"vflip\":\n",
    "        base_transforms.append(A.VerticalFlip(p=1.0))\n",
    "    elif tta_type == \"rotate\":\n",
    "        base_transforms.append(A.Rotate(limit=10, p=1.0))\n",
    "\n",
    "    base_transforms.extend(\n",
    "        [\n",
    "            A.Normalize(\n",
    "                mean=cfg[\"data\"][\"normalization\"][\"mean\"], std=cfg[\"data\"][\"normalization\"][\"std\"], max_pixel_value=255.0\n",
    "            ),\n",
    "            ToTensorV2(),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    return A.Compose(base_transforms)\n",
    "\n",
    "\n",
    "# TTA設定\n",
    "tta_transforms = [None, \"hflip\", \"vflip\"] if cfg[\"model\"].get(\"inference\", {}).get(\"tta_enabled\", True) else [None]\n",
    "print(f\"TTA transforms: {tta_transforms}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# テスト用Dataset\n",
    "class TestDataset(Dataset):\n",
    "    def __init__(self, df, image_dir, transform=None):\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.image_dir = Path(image_dir)\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "\n",
    "        # 画像読み込み（実際のファイル形式・命名規則に応じて修正）\n",
    "        image_path = self.image_dir / f\"{row['image_id']}.png\"\n",
    "        image = cv2.imread(str(image_path))\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        if self.transform:\n",
    "            augmented = self.transform(image=image)\n",
    "            image = augmented[\"image\"]\n",
    "\n",
    "        return image\n",
    "\n",
    "\n",
    "print(\"Test dataset class defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 推論実行\n",
    "def predict_with_tta(models, dataloader, device, use_amp=True):\n",
    "    \"\"\"\n",
    "    モデルアンサンブル + TTA で予測\n",
    "    \"\"\"\n",
    "    all_predictions = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(dataloader, desc=\"Predicting\"):\n",
    "            images = batch.to(device)\n",
    "            batch_predictions = []\n",
    "\n",
    "            # 各モデルで予測\n",
    "            for model in models:\n",
    "                with autocast(enabled=use_amp):\n",
    "                    outputs = model(images)\n",
    "                    probs = torch.sigmoid(outputs).cpu().numpy()\n",
    "                    batch_predictions.append(probs)\n",
    "\n",
    "            # モデル間平均\n",
    "            ensemble_preds = np.mean(batch_predictions, axis=0)\n",
    "            all_predictions.extend(ensemble_preds.flatten())\n",
    "\n",
    "    return np.array(all_predictions)\n",
    "\n",
    "\n",
    "# TTA推論実行\n",
    "tta_predictions = []\n",
    "\n",
    "for tta_type in tta_transforms:\n",
    "    print(f\"\\nRunning inference with TTA: {tta_type}\")\n",
    "\n",
    "    # Dataset・DataLoader作成\n",
    "    test_dataset = TestDataset(\n",
    "        test_df,\n",
    "        cfg[\"paths\"][\"processed_data\"],  # テスト画像ディレクトリ\n",
    "        transform=get_test_transforms(tta_type),\n",
    "    )\n",
    "\n",
    "    test_loader = DataLoader(\n",
    "        test_dataset,\n",
    "        batch_size=cfg[\"train\"][\"batch_size\"] * 2,  # 推論時はバッチサイズ大きめ\n",
    "        shuffle=False,\n",
    "        num_workers=4,\n",
    "        pin_memory=True,\n",
    "    )\n",
    "\n",
    "    # 予測実行\n",
    "    predictions = predict_with_tta(models_list, test_loader, device, use_amp=cfg[\"environment\"][\"mixed_precision\"])\n",
    "\n",
    "    tta_predictions.append(predictions)\n",
    "    print(f\"Predictions shape: {predictions.shape}\")\n",
    "    print(f\"Prediction range: [{predictions.min():.4f}, {predictions.max():.4f}]\")\n",
    "\n",
    "# TTA結果の平均\n",
    "final_predictions = np.mean(tta_predictions, axis=0)\n",
    "print(f\"\\n🎯 Final predictions (TTA ensemble):\")\n",
    "print(f\"  Shape: {final_predictions.shape}\")\n",
    "print(f\"  Range: [{final_predictions.min():.4f}, {final_predictions.max():.4f}]\")\n",
    "print(f\"  Mean: {final_predictions.mean():.4f}\")\n",
    "print(f\"  Std: {final_predictions.std():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 予測分布の可視化\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "# 予測確率分布\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.hist(final_predictions, bins=50, alpha=0.7, edgecolor=\"black\")\n",
    "plt.axvline(\n",
    "    eval_metrics[\"recommended_threshold\"],\n",
    "    color=\"red\",\n",
    "    linestyle=\"--\",\n",
    "    label=f\"Recommended threshold: {eval_metrics['recommended_threshold']:.3f}\",\n",
    ")\n",
    "plt.xlabel(\"Predicted Probability\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.title(\"Test Predictions Distribution\")\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# 累積分布\n",
    "plt.subplot(1, 2, 2)\n",
    "sorted_preds = np.sort(final_predictions)\n",
    "cumulative = np.arange(1, len(sorted_preds) + 1) / len(sorted_preds)\n",
    "plt.plot(sorted_preds, cumulative)\n",
    "plt.axvline(eval_metrics[\"recommended_threshold\"], color=\"red\", linestyle=\"--\")\n",
    "plt.xlabel(\"Predicted Probability\")\n",
    "plt.ylabel(\"Cumulative Probability\")\n",
    "plt.title(\"Cumulative Distribution\")\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"test_predictions_distribution.png\", dpi=300, bbox_inches=\"tight\")\n",
    "plt.show()\n",
    "\n",
    "# 予測統計\n",
    "threshold = eval_metrics[\"recommended_threshold\"]\n",
    "positive_predictions = (final_predictions >= threshold).sum()\n",
    "positive_ratio = positive_predictions / len(final_predictions)\n",
    "\n",
    "print(f\"\\n📊 Test Predictions Summary:\")\n",
    "print(f\"  Total samples: {len(final_predictions)}\")\n",
    "print(f\"  Predicted positive (≥{threshold:.3f}): {positive_predictions} ({positive_ratio:.2%})\")\n",
    "print(f\"  Predicted negative (<{threshold:.3f}): {len(final_predictions) - positive_predictions} ({1 - positive_ratio:.2%})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 提出ファイル作成\n",
    "def create_submission_file(test_df, predictions, threshold, output_dir=\"submissions\"):\n",
    "    \"\"\"\n",
    "    Kaggle提出用CSVファイルを作成\n",
    "    \"\"\"\n",
    "    Path(output_dir).mkdir(exist_ok=True)\n",
    "\n",
    "    # 予測確率版（主要提出）\n",
    "    submission_proba = test_df[[\"image_id\"]].copy()\n",
    "    submission_proba[\"aneurysm\"] = predictions  # 確率値をそのまま\n",
    "\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    proba_filename = f\"{output_dir}/{cfg['experiment']['id']}_proba_{timestamp}.csv\"\n",
    "    submission_proba.to_csv(proba_filename, index=False)\n",
    "\n",
    "    # 二値予測版（バックアップ）\n",
    "    submission_binary = test_df[[\"image_id\"]].copy()\n",
    "    submission_binary[\"aneurysm\"] = (predictions >= threshold).astype(int)\n",
    "\n",
    "    binary_filename = f\"{output_dir}/{cfg['experiment']['id']}_binary_th{threshold:.3f}_{timestamp}.csv\"\n",
    "    submission_binary.to_csv(binary_filename, index=False)\n",
    "\n",
    "    return proba_filename, binary_filename\n",
    "\n",
    "\n",
    "# 提出ファイル生成\n",
    "proba_file, binary_file = create_submission_file(test_df, final_predictions, eval_metrics[\"recommended_threshold\"])\n",
    "\n",
    "print(f\"\\n📄 Submission files created:\")\n",
    "print(f\"  Probability version: {proba_file}\")\n",
    "print(f\"  Binary version: {binary_file}\")\n",
    "\n",
    "# 提出ファイル内容確認\n",
    "submission_df = pd.read_csv(proba_file)\n",
    "print(f\"\\n📋 Submission file preview:\")\n",
    "print(submission_df.head(10))\n",
    "print(f\"\\nSubmission statistics:\")\n",
    "print(submission_df[\"aneurysm\"].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kaggle API提出準備\n",
    "def submit_to_kaggle(submission_file, competition_name, message):\n",
    "    \"\"\"\n",
    "    Kaggle APIで提出\n",
    "    \"\"\"\n",
    "    try:\n",
    "        cmd = f'kaggle competitions submit -c {competition_name} -f {submission_file} -m \"{message}\"'\n",
    "        result = subprocess.run(cmd, shell=True, capture_output=True, text=True)\n",
    "\n",
    "        if result.returncode == 0:\n",
    "            print(f\"✅ Successfully submitted to Kaggle!\")\n",
    "            print(f\"Output: {result.stdout}\")\n",
    "            return True\n",
    "        else:\n",
    "            print(f\"❌ Submission failed: {result.stderr}\")\n",
    "            return False\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error during submission: {str(e)}\")\n",
    "        return False\n",
    "\n",
    "\n",
    "# 提出実行\n",
    "git_sha = subprocess.check_output([\"git\", \"rev-parse\", \"HEAD\"]).decode(\"ascii\").strip()[:8]\n",
    "submission_message = cfg[\"kaggle\"][\"submission_message\"].format(git_sha=git_sha)\n",
    "\n",
    "print(f\"\\n🚀 Submitting to Kaggle...\")\n",
    "print(f\"Competition: {cfg['kaggle']['competition']}\")\n",
    "print(f\"File: {proba_file}\")\n",
    "print(f\"Message: {submission_message}\")\n",
    "\n",
    "# 実際の提出（コメントアウトしている場合は手動で実行）\n",
    "success = submit_to_kaggle(proba_file, cfg[\"kaggle\"][\"competition\"], submission_message)\n",
    "\n",
    "if success:\n",
    "    print(\"\\n🏆 Submission completed!\")\n",
    "else:\n",
    "    print(\"\\n⚠️  Manual submission required:\")\n",
    "    print(f\"   kaggle competitions submit -c {cfg['kaggle']['competition']} -f {proba_file} -m '{submission_message}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 推論結果保存（トレーサビリティ用）\n",
    "inference_manifest = {\n",
    "    \"experiment_id\": cfg[\"experiment\"][\"id\"],\n",
    "    \"inference_date\": datetime.now().isoformat(),\n",
    "    \"git_sha\": git_sha,\n",
    "    # モデル情報\n",
    "    \"models_used\": [f\"fold_{i}_best.pth\" for i in range(len(models_list))],\n",
    "    \"model_architecture\": cfg[\"model\"][\"architecture\"],\n",
    "    # 推論設定\n",
    "    \"tta_enabled\": len(tta_transforms) > 1,\n",
    "    \"tta_methods\": tta_transforms,\n",
    "    \"threshold_used\": float(eval_metrics[\"recommended_threshold\"]),\n",
    "    \"mixed_precision\": cfg[\"environment\"][\"mixed_precision\"],\n",
    "    # 予測統計\n",
    "    \"test_samples\": len(final_predictions),\n",
    "    \"prediction_statistics\": {\n",
    "        \"mean\": float(final_predictions.mean()),\n",
    "        \"std\": float(final_predictions.std()),\n",
    "        \"min\": float(final_predictions.min()),\n",
    "        \"max\": float(final_predictions.max()),\n",
    "        \"positive_predictions\": int(positive_predictions),\n",
    "        \"positive_ratio\": float(positive_ratio),\n",
    "    },\n",
    "    # 提出情報\n",
    "    \"submission_files\": {\"probability\": proba_file, \"binary\": binary_file},\n",
    "    \"kaggle_submission\": {\"competition\": cfg[\"kaggle\"][\"competition\"], \"message\": submission_message, \"success\": success},\n",
    "    # 品質指標（学習時参照）\n",
    "    \"training_performance\": {\n",
    "        \"cv_auc\": eval_metrics[\"cv_mean_auc\"],\n",
    "        \"oof_auc\": eval_metrics[\"oof_auc\"],\n",
    "        \"cv_reliability_score\": eval_metrics[\"quality_audit\"][\"cv_reliability_score\"],\n",
    "    },\n",
    "}\n",
    "\n",
    "# マニフェスト保存\n",
    "with open(\"inference_manifest.json\", \"w\") as f:\n",
    "    json.dump(inference_manifest, f, indent=2)\n",
    "\n",
    "# テスト予測も保存（後でアンサンブルに使用可能）\n",
    "test_predictions_df = test_df[[\"image_id\"]].copy()\n",
    "test_predictions_df[\"predicted_probability\"] = final_predictions\n",
    "test_predictions_df[\"experiment_id\"] = cfg[\"experiment\"][\"id\"]\n",
    "test_predictions_df.to_csv(\"test_predictions.csv\", index=False)\n",
    "\n",
    "print(f\"\\n💾 Inference artifacts saved:\")\n",
    "print(f\"  - inference_manifest.json\")\n",
    "print(f\"  - test_predictions.csv\")\n",
    "print(f\"  - test_predictions_distribution.png\")\n",
    "print(f\"  - {proba_file}\")\n",
    "print(f\"  - {binary_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Google Drive バックアップ\n",
    "backup_dir = f\"/content/drive/MyDrive/rsna-aneurysm/{cfg['experiment']['id']}\"\n",
    "!mkdir -p \"{backup_dir}/submissions\"\n",
    "\n",
    "# 重要ファイルをDriveにコピー\n",
    "!cp inference_manifest.json \"{backup_dir}/\"\n",
    "!cp test_predictions.csv \"{backup_dir}/\"\n",
    "!cp test_predictions_distribution.png \"{backup_dir}/\"\n",
    "!cp \"{proba_file}\" \"{backup_dir}/submissions/\"\n",
    "!cp \"{binary_file}\" \"{backup_dir}/submissions/\"\n",
    "\n",
    "print(f\"\\n☁️  Files backed up to Google Drive: {backup_dir}\")\n",
    "\n",
    "# 実験完了サマリー\n",
    "print(f\"\\n\" + \"=\" * 60)\n",
    "print(f\"🎯 EXPERIMENT {cfg['experiment']['id'].upper()} - INFERENCE COMPLETED\")\n",
    "print(f\"=\" * 60)\n",
    "print(f\"Model: {cfg['model']['architecture']}\")\n",
    "print(f\"CV Performance: {eval_metrics['cv_mean_auc']:.4f} ± {eval_metrics['cv_std_auc']:.4f}\")\n",
    "print(f\"Test Predictions: {len(final_predictions)} samples\")\n",
    "print(f\"Predicted Positive: {positive_predictions} ({positive_ratio:.2%})\")\n",
    "print(f\"Kaggle Submission: {'✅ Success' if success else '⚠️ Manual required'}\")\n",
    "print(f\"\\nNext Steps:\")\n",
    "print(f\"  1. Monitor Kaggle LB score\")\n",
    "print(f\"  2. Update experiments.csv with LB results\")\n",
    "print(f\"  3. Plan next experiment (exp0002)\")\n",
    "print(f\"\\n🚀 Ready for next experiment!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}